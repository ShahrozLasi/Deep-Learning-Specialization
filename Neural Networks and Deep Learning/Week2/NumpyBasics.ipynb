{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NumpyBasics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed8Tlihr9Prm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpfHYZ909Xx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def basic_sigmoid(x):\n",
        "    \"\"\"\n",
        "    Compute sigmoid of x.\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar\n",
        "\n",
        "    Return:\n",
        "    s -- sigmoid(x)\n",
        "    \"\"\"\n",
        "    s = 1/(1+math.exp(-x))\n",
        "    \n",
        "    return s\n",
        "\n",
        "  ## A vector won't work for the function above."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgeOMMvY9iwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    \"\"\"\n",
        "    Computes the sigmoid of x\n",
        "\n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array of any size\n",
        "\n",
        "    Return:\n",
        "    s -- sigmoid(x)\n",
        "    \"\"\"\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    \n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5B858Rp-tWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_derivative(x):\n",
        "    \"\"\"\n",
        "    Computes the gradient of the sigmoid function with respect to its input x.\n",
        "    \n",
        "    Arguments:\n",
        "    x -- A scalar or numpy array\n",
        "\n",
        "    Return:\n",
        "    ds -- Your computed gradient.\n",
        "    \"\"\"\n",
        "    s = sigmoid(x)\n",
        "    ds = np.multiply(s, 1-s)\n",
        "    \n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEk7G1v5-8IJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image2vector(image):\n",
        "    \"\"\"\n",
        "    Argument:\n",
        "    image -- a numpy array of shape (length, height, depth)\n",
        "    \n",
        "    Returns:\n",
        "    v -- a vector of shape (length*height*depth, 1)\n",
        "    \"\"\"\n",
        "    v = image.reshape(image.shape[0]*image.shape[1]*image.shape[2], 1)\n",
        "    \n",
        "    return v\n",
        "\n",
        "  ## In Logistic regression, the reshaped 'v' in passed as a feature.\n",
        "  ## Each image contains RGB values."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vishOfzZ_bLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalizeRows(x):\n",
        "    \"\"\"\n",
        "    Normalizes each row of the matrix x (to have unit length).\n",
        "    \n",
        "    Argument:\n",
        "    x -- A numpy matrix of shape (n, m)\n",
        "    \n",
        "    Returns:\n",
        "    x -- The normalized (by row) numpy matrix. You are allowed to modify x.\n",
        "    \"\"\"\n",
        "    \n",
        "    x_norm = np.linalg.norm(x, axis =1, keepdims = True) # axis = 1 -> for vertical sum, keepdims -> to have the same column/row dimension.\n",
        "    \n",
        "    # Divide x by its norm.\n",
        "    x = x/x_norm\n",
        "    \n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxtahtaaABuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    \"\"\"Calculates the softmax for each row of the input x.\n",
        "\n",
        "    Argument:\n",
        "    x -- A numpy matrix of shape (m,n)\n",
        "\n",
        "    Returns:\n",
        "    s -- A numpy matrix equal to the softmax of x, of shape (m,n)\n",
        "    \"\"\"\n",
        "    \n",
        "    x_exp = np.exp(x)\n",
        "    # Create a vector x_sum that sums each row of x_exp.\n",
        "    x_sum = np.sum(x_exp, axis = 1, keepdims = True)\n",
        "    # Compute softmax(x) by dividing x_exp by x_sum. \n",
        "    s = x_exp/x_sum\n",
        "    \n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q6h0gTrcmJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L1(yhat, y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    yhat -- vector of size m (predicted labels)\n",
        "    y -- vector of size m (true labels)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- the value of the L1 loss function defined above\n",
        "    \"\"\"\n",
        "    \n",
        "    loss = np.sum(np.abs(y - yhat))\n",
        "    \n",
        "    return loss\n",
        "\n",
        "def L2(yhat, y):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    yhat -- vector of size m (predicted labels)\n",
        "    y -- vector of size m (true labels)\n",
        "    \n",
        "    Returns:\n",
        "    loss -- the value of the L2 loss function defined above\n",
        "    \"\"\"\n",
        "    loss = np.sum(np.square(y - yhat))\n",
        "\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}