{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Numbers_SignLanguage.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNpibE78J06cCh9plXkm2sw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SzXg-HehxjSp","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","\n","from tensorflow.python.framework import ops\n","import matplotlib.pyplot as plt\n","import math\n","import numpy as np\n","import h5py\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fEZHi3sCk45k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"outputId":"a9c5198f-db0e-48f1-a733-bba3a3409eb3","executionInfo":{"status":"ok","timestamp":1585506978829,"user_tz":-120,"elapsed":24552,"user":{"displayName":"shahroz lasi","photoUrl":"","userId":"12196692998240518202"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount =True)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AcYG5uV0ziUm","colab_type":"code","colab":{}},"source":["## Helper Functions\n","\n","import h5py\n","import numpy as np\n","import tensorflow as tf\n","import math\n","\n","def load_dataset():\n","    train_dataset = h5py.File('/content/drive/My Drive/datasets/train_signs.h5', \"r\")\n","    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n","    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n","\n","    test_dataset = h5py.File('/content/drive/My Drive/datasets/test_signs.h5', \"r\")\n","    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n","    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n","\n","    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n","    \n","    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n","    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n","    \n","    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n","\n","\n","def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n","    \"\"\"\n","    Creates a list of random minibatches from (X, Y)\n","    \n","    Arguments:\n","    X -- input data, of shape (input size, number of examples)\n","    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n","    mini_batch_size - size of the mini-batches, integer\n","    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n","    \n","    Returns:\n","    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n","    \"\"\"\n","    \n","    m = X.shape[1]                  # number of training examples\n","    mini_batches = []\n","    np.random.seed(seed)\n","    \n","    # Step 1: Shuffle (X, Y)\n","    permutation = list(np.random.permutation(m))\n","    shuffled_X = X[:, permutation]\n","    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n","\n","    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n","    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n","    for k in range(0, num_complete_minibatches):\n","        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n","        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","    \n","    # Handling the end case (last mini-batch < mini_batch_size)\n","    if m % mini_batch_size != 0:\n","        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n","        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n","        mini_batch = (mini_batch_X, mini_batch_Y)\n","        mini_batches.append(mini_batch)\n","    \n","    return mini_batches\n","\n","def convert_to_one_hot(Y, C):\n","    Y = np.eye(C)[Y.reshape(-1)].T\n","    return Y\n","\n","\n","def predict(X, parameters):\n","    \n","    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n","    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n","    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n","    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n","    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n","    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n","    \n","    params = {\"W1\": W1,\n","              \"b1\": b1,\n","              \"W2\": W2,\n","              \"b2\": b2,\n","              \"W3\": W3,\n","              \"b3\": b3}\n","    \n","    x = tf.placeholder(\"float\", [12288, 1])\n","    \n","    z3 = forward_propagation_for_predict(x, params)\n","    p = tf.argmax(z3)\n","    \n","    sess = tf.Session()\n","    prediction = sess.run(p, feed_dict = {x: X})\n","        \n","    return prediction\n","\n","def forward_propagation_for_predict(X, parameters):\n","    \"\"\"\n","    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n","    \n","    Arguments:\n","    X -- input dataset placeholder, of shape (input size, number of examples)\n","    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n","                  the shapes are given in initialize_parameters\n","\n","    Returns:\n","    Z3 -- the output of the last LINEAR unit\n","    \"\"\"\n","    \n","    # Retrieve the parameters from the dictionary \"parameters\" \n","    W1 = parameters['W1']\n","    b1 = parameters['b1']\n","    W2 = parameters['W2']\n","    b2 = parameters['b2']\n","    W3 = parameters['W3']\n","    b3 = parameters['b3'] \n","                                                           # Numpy Equivalents:\n","    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n","    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n","    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n","    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n","    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n","    \n","    return Z3\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcH7_4cszy4T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"7277b696-0f3b-4caf-f140-041ef4cd97ae","executionInfo":{"status":"ok","timestamp":1585495058330,"user_tz":-120,"elapsed":739,"user":{"displayName":"shahroz lasi","photoUrl":"","userId":"12196692998240518202"}}},"source":["## Compute Loss of one training exampple using TensorFlow\n","y_hat = tf.constant(36, name = 'y_hat')  # Define y_hat constant. Set to 36\n","y     = tf.constant(39, name = 'y')      # Define y. Set to 39\n","\n","loss = tf.Variable((y-y_hat)**2, name = 'loss')  # Create a variable for loss\n","tf.compat.v1.disable_eager_execution()\n","\n","init = tf.compat.v1.global_variables_initializer()  # When init is run later, the loss variable will be initialized and ready to be computed.\n","\n","with tf.compat.v1.Session() as session:    # Create a session and print the output\n","  session.run(init)                        # Initialize the variables\n","  print(session.run(loss))                 # Prints the loss\n","\n","\n","## Writing and running programs in TF has the following steps (TensorFlow 1):\n","# 1. Create Tensors variables that are not yet executed/evaluated.\n","# 2. Write operations between those Tensors\n","# 3. Initialize your Tensors\n","# 4. Create a session\n","# 5. Run the session. This will run the operations you had written above.\n","\n","a = tf.constant(2)\n","b = tf.constant(10)\n","c = tf.multiply(a,b)\n","print(c)\n","sess = tf.compat.v1.Session()\n","print(sess.run(c))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["9\n","Tensor(\"Mul_1:0\", shape=(), dtype=int32)\n","20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"heSFOOBcdHPv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"fed730c2-3ce7-4a2e-846b-7777b66706ee","executionInfo":{"status":"ok","timestamp":1585504964955,"user_tz":-120,"elapsed":845,"user":{"displayName":"shahroz lasi","photoUrl":"","userId":"12196692998240518202"}}},"source":["## A placeholder is an object whose value you can specipy only later. To specidy values for a placeholder, you can pass in values by using a \"feed dictionary\".\n","# Change the value of x in the feed_dict\n","\n","x = tf.compat.v1.placeholder(tf.int64, name = 'x')\n","print(sess.run(2 * x, feed_dict = {x: 3}))\n","sess.close()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["6\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fw2UgPaqdpGa","colab_type":"text"},"source":["## Linear Function"]},{"cell_type":"code","metadata":{"id":"6nDgH-42drLA","colab_type":"code","colab":{}},"source":["def linear_function():\n","    \"\"\"\n","    Implements a linear function: \n","            Initializes X to be a random tensor of shape (3,1)\n","            Initializes W to be a random tensor of shape (4,3)\n","            Initializes b to be a random tensor of shape (4,1)\n","    Returns: \n","    result -- runs the session for Y = WX + b \n","    \"\"\"\n","    \n","    np.random.seed(1)\n","    \n","    \"\"\"\n","    Note, to ensure that the \"random\" numbers generated match the expected results,\n","    please create the variables in the order given in the starting code below.\n","    \"\"\"\n","    X = tf.constant(np.random.randn(3,1), name = \"X\")\n","    W = tf.constant(np.random.randn(4,3), name = \"W\")\n","    b = tf.constant(np.random.randn(4,1), name = \"b\")\n","    Y = tf.add(tf.matmul(W,X), b)\n","    \n","    # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate\n","    sess = tf.compat.v1.Session()\n","    result = sess.run(Y)\n","    \n","    # close the session \n","    sess.close()\n","\n","    return result\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MsCP7kqaewip","colab_type":"text"},"source":["## Computing the Sigmoid"]},{"cell_type":"code","metadata":{"id":"zciuD6jlez6v","colab_type":"code","colab":{}},"source":["def sigmoid(z):\n","    \"\"\"\n","    Computes the sigmoid of z\n","    \n","    Arguments:\n","    z -- input value, scalar or vector\n","    \n","    Returns: \n","    results -- the sigmoid of z\n","    \"\"\"\n","    \n","    # Create a placeholder for x. Name it 'x'.\n","    x = tf.compat.v1.placeholder(tf.float32, name = 'x')\n","\n","    # compute sigmoid(x)\n","    sigmoid = tf.sigmoid(x)\n","\n","    # Create a session, and run it. Please use the method 2 explained above. \n","    # You should use a feed_dict to pass z's value to x. \n","    sess = tf.compat.v1.Session()\n","    # Run session and call the output \"result\"\n","    result = sess.run(sigmoid, feed_dict = {x:z})\n","    sess.close()\n","\n","    \n","    return result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TXk1tbYRgFTV","colab_type":"text"},"source":["## Computing the cost"]},{"cell_type":"code","metadata":{"id":"1J3v3uXdgG5a","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: cost\n","\n","def cost(logits, labels):\n","    \"\"\"\n","    Computes the cost using the sigmoid cross entropy\n","    \n","    Arguments:\n","    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n","    labels -- vector of labels y (1 or 0) \n","    \n","    Returns:\n","    cost -- runs the session of the cost (formula (2))\n","    \"\"\"\n","    \n","    # Create the placeholders for \"logits\" (z) and \"labels\" (y) \n","    z = tf.placeholder(tf.float32, name = 'z')\n","    y = tf.placeholder(tf.float32, name = 'y')\n","    \n","    # Use the loss function \n","    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z, labels=y)\n","    \n","    # Create a session \n","    sess = tf.Session()\n","    \n","    # Run the session.\n","    cost = sess.run(cost, feed_dict = {z:logits, y:labels})\n","    \n","    # Close the session.\n","    sess.close()\n","    \n","    return cost"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tkSJqW2xhFpK","colab_type":"text"},"source":["## One-Hot Encoding"]},{"cell_type":"code","metadata":{"id":"gghAyas5jqu0","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: one_hot_matrix\n","\n","def one_hot_matrix(labels, C):\n","    \"\"\"\n","    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n","                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n","                     will be 1. \n","                     \n","    Arguments:\n","    labels -- vector containing the labels \n","    C -- number of classes, the depth of the one hot dimension\n","    \n","    Returns: \n","    one_hot -- one hot matrix\n","    \"\"\"\n","    \n","    # Create a tf.constant equal to C (depth)\n","    C = tf.constant(C, name = 'C' )\n","    \n","    # Use tf.one_hot, be careful with the axis\n","    one_hot_matrix = tf.one_hot(labels, depth = C, axis = 0)\n","    \n","    # Create the session\n","    sess = tf.Session()\n","    \n","    # Run the session\n","    one_hot = sess.run(one_hot_matrix)\n","    \n","    # Close the session\n","    sess.close()\n","    \n","    return one_hot"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYdQwJDrj2KL","colab_type":"text"},"source":["## Initialize with zeros and ones"]},{"cell_type":"code","metadata":{"id":"kbPT_SKSj47i","colab_type":"code","colab":{}},"source":["def ones(shape):\n","    \"\"\"\n","    Creates an array of ones of dimension shape\n","    \n","    Arguments:\n","    shape -- shape of the array you want to create\n","        \n","    Returns: \n","    ones -- array containing only ones\n","    \"\"\"\n","    # Create \"ones\" tensor using tf.ones(...)\n","    ones = tf.ones(shape)\n","    \n","    # Create the session\n","    sess = tf.Session()\n","    \n","    # Run the session to compute 'ones'\n","    ones = sess.run(ones)\n","    \n","    # Close the session.\n","    sess.close()\n","\n","    return ones"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wcRKTT1WkQcu","colab_type":"text"},"source":["# Building a Neural Network in TensorFlow"]},{"cell_type":"code","metadata":{"id":"RZgSQcsckP1z","colab_type":"code","colab":{}},"source":["# Loading the dataset\n","X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d4GJrfrXmYk3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":299},"outputId":"69248dbe-8bac-440f-9040-dc5819b60493","executionInfo":{"status":"ok","timestamp":1585507563553,"user_tz":-120,"elapsed":870,"user":{"displayName":"shahroz lasi","photoUrl":"","userId":"12196692998240518202"}}},"source":["# Example of a picture\n","index = 0\n","plt.imshow(X_train_orig[index])\n","plt.title(\"Label of the Image is {}\".format(np.squeeze(Y_train_orig[:, index])))\n","print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"],"execution_count":40,"outputs":[{"output_type":"stream","text":["y = 5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEPhidzgKAl/sDkdB4Ivd4SgI/j8J2ZffyoqMVgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"BWl4AermmlXP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"outputId":"2cf2360d-64c6-4499-c310-30d451805f5d","executionInfo":{"status":"ok","timestamp":1585507576850,"user_tz":-120,"elapsed":845,"user":{"displayName":"shahroz lasi","photoUrl":"","userId":"12196692998240518202"}}},"source":["# Flatten the training and test images\n","X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n","X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n","# Normalize image vectors\n","X_train = X_train_flatten/255.\n","X_test = X_test_flatten/255.\n","# Convert training and test labels to one hot matrices\n","Y_train = convert_to_one_hot(Y_train_orig, 6)\n","Y_test = convert_to_one_hot(Y_test_orig, 6)\n","\n","print (\"number of training examples = \" + str(X_train.shape[1]))\n","print (\"number of test examples = \" + str(X_test.shape[1]))\n","print (\"X_train shape: \" + str(X_train.shape))\n","print (\"Y_train shape: \" + str(Y_train.shape))\n","print (\"X_test shape: \" + str(X_test.shape))\n","print (\"Y_test shape: \" + str(Y_test.shape))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["number of training examples = 1080\n","number of test examples = 120\n","X_train shape: (12288, 1080)\n","Y_train shape: (6, 1080)\n","X_test shape: (12288, 120)\n","Y_test shape: (6, 120)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lvgnGu4HnfVg","colab_type":"text"},"source":["## Create placeholders"]},{"cell_type":"code","metadata":{"id":"-pMuicrxnbqC","colab_type":"code","colab":{}},"source":["def create_placeholders(n_x, n_y):\n","    \"\"\"\n","    Creates the placeholders for the tensorflow session.\n","    \n","    Arguments:\n","    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n","    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n","    \n","    Returns:\n","    X -- placeholder for the data input, of shape [n_x, None] and dtype \"tf.float32\"\n","    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"tf.float32\"\n","    \n","    \"\"\"\n","    X = tf.placeholder(shape=(n_x, None), dtype = tf.float32, name = \"X\") # None : because the number of examples in train/test is different.\n","    Y = tf.placeholder(shape=(n_y, None), dtype = tf.float32, name = \"Y\")\n","    \n","    return X, Y\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eTwIGEp1omYy","colab_type":"text"},"source":["## Initializing the parameters"]},{"cell_type":"code","metadata":{"id":"jA7BgJBNoo-x","colab_type":"code","colab":{}},"source":["def initialize_parameters():\n","    \"\"\"\n","    Initializes parameters to build a neural network with tensorflow. The shapes are:\n","                        W1 : [25, 12288]\n","                        b1 : [25, 1]\n","                        W2 : [12, 25]\n","                        b2 : [12, 1]\n","                        W3 : [6, 12]\n","                        b3 : [6, 1]\n","    \n","    Returns:\n","    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n","    \"\"\"\n","    \n","    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n","        \n","    W1 = tf.get_variable(shape= (25,12288), name = \"W1\", initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n","    b1 = tf.get_variable(shape= (25,1), name = \"b1\", initializer=tf.zeros_initializer())\n","    W2 = tf.get_variable(shape= (12,25), name = \"W2\", initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n","    b2 = tf.get_variable(shape= (12,1), name = \"b2\", initializer=tf.zeros_initializer())\n","    W3 = tf.get_variable(shape= (6,12), name = \"W3\", initializer=tf.contrib.layers.xavier_initializer(seed = 1))\n","    b3 = tf.get_variable(shape= (6,1), name = \"b3\", initializer=tf.zeros_initializer())\n","\n","    parameters = {\"W1\": W1,\n","                  \"b1\": b1,\n","                  \"W2\": W2,\n","                  \"b2\": b2,\n","                  \"W3\": W3,\n","                  \"b3\": b3}\n","    \n","    return parameters"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6MGKtHQcpsyG","colab_type":"text"},"source":["## Forward Propagation"]},{"cell_type":"code","metadata":{"id":"aKzUZn9ppv30","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: forward_propagation\n","\n","def forward_propagation(X, parameters):\n","    \"\"\"\n","    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n","    \n","    Arguments:\n","    X -- input dataset placeholder, of shape (input size, number of examples)\n","    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n","                  the shapes are given in initialize_parameters\n","\n","    Returns:\n","    Z3 -- the output of the last LINEAR unit\n","    \"\"\"\n","    \n","    # Retrieve the parameters from the dictionary \"parameters\" \n","    W1 = parameters['W1']\n","    b1 = parameters['b1']\n","    W2 = parameters['W2']\n","    b2 = parameters['b2']\n","    W3 = parameters['W3']\n","    b3 = parameters['b3']\n","    \n","                                                                    # Numpy Equivalents:\n","    Z1 = tf.add(tf.matmul(W1, X), b1)                               # Z1 = np.dot(W1, X) + b1\n","    A1 = tf.nn.relu(Z1)                                             # A1 = relu(Z1)\n","    Z2 = tf.add(tf.matmul(W2,A1), b2)                               # Z2 = np.dot(W2, A1) + b2\n","    A2 = tf.nn.relu(Z2)                                             # A2 = relu(Z2)\n","    Z3 = tf.add(tf.matmul(W3,A2), b3)                               # Z3 = np.dot(W3, A2) + b3\n","    \n","    return Z3"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5vsFE7dtqcTb","colab_type":"text"},"source":["## Compute Cost"]},{"cell_type":"code","metadata":{"id":"4aob2T-jqdlR","colab_type":"code","colab":{}},"source":["def compute_cost(Z3, Y):\n","    \"\"\"\n","    Computes the cost\n","    \n","    Arguments:\n","    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n","    Y -- \"true\" labels vector placeholder, same shape as Z3\n","    \n","    Returns:\n","    cost - Tensor of the cost function\n","    \"\"\"\n","    logits = tf.transpose(Z3)\n","    labels = tf.transpose(Y)\n","    \n","    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels= labels))\n","    \n","    return cost"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"63xG-9n0q59Q","colab_type":"text"},"source":["## Backward Propagation & parameter updates"]},{"cell_type":"code","metadata":{"id":"SvinGePlq_M9","colab_type":"code","colab":{}},"source":["def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n","          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n","    \"\"\"\n","    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n","    \n","    Arguments:\n","    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n","    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n","    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n","    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n","    learning_rate -- learning rate of the optimization\n","    num_epochs -- number of epochs of the optimization loop\n","    minibatch_size -- size of a minibatch\n","    print_cost -- True to print the cost every 100 epochs\n","    \n","    Returns:\n","    parameters -- parameters learnt by the model. They can then be used to predict.\n","    \"\"\"\n","    \n","    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n","    tf.set_random_seed(1)                             # to keep consistent results\n","    seed = 3                                          # to keep consistent results\n","    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n","    n_y = Y_train.shape[0]                            # n_y : output size\n","    costs = []                                        # To keep track of the cost\n","    \n","    # Create Placeholders of shape (n_x, n_y)\n","    X, Y = create_placeholders(n_x, n_y)\n","    \n","    # Initialize parameters\n","    parameters = initialize_parameters()\n","    \n","    # Forward propagation: Build the forward propagation in the tensorflow graph\n","    Z3 = forward_propagation(X, parameters)\n","    \n","    # Cost function: Add cost function to tensorflow graph\n","    cost = compute_cost(Z3, Y)\n","    \n","    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n","    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n","    \n","    # Initialize all the variables\n","    init = tf.global_variables_initializer()\n","\n","    # Start the session to compute the tensorflow graph\n","    with tf.Session() as sess:\n","        \n","        # Run the initialization\n","        sess.run(init)\n","        \n","        # Do the training loop\n","        for epoch in range(num_epochs):\n","\n","            epoch_cost = 0.                       # Defines a cost related to an epoch\n","            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n","            seed = seed + 1\n","            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n","\n","            for minibatch in minibatches:\n","\n","                # Select a minibatch\n","                (minibatch_X, minibatch_Y) = minibatch\n","                \n","                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n","                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n","                \n","                epoch_cost += minibatch_cost / minibatch_size\n","\n","            # Print the cost every epoch\n","            if print_cost == True and epoch % 100 == 0:\n","                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n","            if print_cost == True and epoch % 5 == 0:\n","                costs.append(epoch_cost)\n","                \n","        # plot the cost\n","        plt.plot(np.squeeze(costs))\n","        plt.ylabel('cost')\n","        plt.xlabel('iterations (per fives)')\n","        plt.title(\"Learning rate =\" + str(learning_rate))\n","        plt.show()\n","\n","        # lets save the parameters in a variable\n","        parameters = sess.run(parameters)\n","        print (\"Parameters have been trained!\")\n","\n","        # Calculate the correct predictions\n","        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n","\n","        # Calculate accuracy on the test set\n","        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n","\n","        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n","        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n","        \n","        return parameters"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"09oa7yx_tVuH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":292},"outputId":"f4ea82ba-60ed-4f3e-f8c0-72cb330e9051","executionInfo":{"status":"error","timestamp":1585509784653,"user_tz":-120,"elapsed":868,"user":{"displayName":"shahroz lasi","photoUrl":"","userId":"12196692998240518202"}}},"source":["parameters = model(X_train, Y_train, X_test, Y_test)"],"execution_count":48,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-aa22b73f05b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-47-184f0f4a7909>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                         \u001b[0;31m# to be able to rerun the model without overwriting tf variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# to keep consistent results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m                                          \u001b[0;31m# to keep consistent results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mn_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m                          \u001b[0;31m# (n_x: input size, m : number of examples in the train set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'set_random_seed'"]}]}]}